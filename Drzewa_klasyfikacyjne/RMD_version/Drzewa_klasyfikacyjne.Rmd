---
title: "Drzewa klasyfikacyjne"
author: "Michał Żychowski"
date: "2023-05-26"
output:
  word_document: default
  html_document: default
  pdf_document: default
---



---
## Przygotowanie danych
Zaczynajmy od importu naszej bazy danych oraz niezbędnych bibliotek.

```{r,warning=FALSE,message=FALSE}
library(readxl)
dane <- read_excel("../data/dane.xlsx")
library(MASS)
library(maptree)
library(rpart)
library(rpart.plot)
library(party)
library(class)
```


Generujemy ramkę danych a następnie usuwamy braki danych
```{r}
dane_pierwotne <- data.frame(dane)
Dane <- na.omit(data.frame(dane_pierwotne))
head(Dane)
```


## Tworzenie zbioru uczącego oraz testowego
Przy tworzeniu naszych zbiorów uczących, losowo wybieramy rekordy z naszej ramki danych i przypisujemy je do odpowiednich zbiorów.

```{r}
Indeksy <- sample(1:nrow(dane),nrow(dane)/2,replace = FALSE)

zbior_uczacy = dane[Indeksy, ]
zbior_testowy = dane[-Indeksy, ]

head(zbior_uczacy)
head(zbior_testowy)
```


## Tworzymy model drzewa
Tworzymy go za pomocą funkcji rpart, wykorzystując zbiór uczący. Ponieważ nasze zmienne są jakościowe, wybieramy metodę "class".

```{r}
Drzewo <- rpart(zbior_uczacy$`Prawo jazdy`~.,zbior_uczacy,method = "class")
```

Dla naszego drzewa możemy sprawdzić parametry oraz liczbę gałęzi.

```{r}
Drzewo$parms
Drzewo$numresp
```

W przypadku gdy wygenerowane drzewo jest bardzo rozległe, możemy spróbować je przyciąć. Choć w naszym przypadku liczba gałęzi jest dość mała, warto sprawdzić, czy przycięcie drzewa nie spowoduje poprawy jego jakości.

```{r}
Model.optimal<-which.min(Drzewo$cptable[,4])
CP.optimal<-Drzewo$cptable[Model.optimal,1]
Drzewo2<-prune(Drzewo,cp=Model.optimal)
```

## Weryfikacja naszych modeli
Teraz, gdy mamy już nasze modele, możemy sprawdzić ich dopasowanie do zbioru uczącego dla naszego pierwotnego drzewa.

```{r, results='hold'}
prediction1<-predict(Drzewo,zbior_uczacy,type = "class")

print("Tabela dobroci klasyfikacji")
table(predykacja=prediction1,prawdziwe=zbior_uczacy$`Prawo jazdy`)

print("Obliczanie błędu predykcji")
error1<-mean(prediction1 != zbior_uczacy$`Prawo jazdy`)
error1
```

oraz dla przyciętego drzewa

```{r, results='hold'}
prediction2<-predict(Drzewo2,zbior_uczacy,type = "class")

print("Tabela dobroci klasyfikacji")
table(predykacja=prediction2,prawdziwe=zbior_uczacy$`Prawo jazdy`)

print("Obliczanie błędu predykcji")
error2<-mean(prediction2 != zbior_uczacy$`Prawo jazdy`)
error2
```

Zauważamy, że nasze przycięte drzewo ma większy błąd predykcji. Niemniej jednak, nie powinniśmy go jeszcze odrzucać, ponieważ istnieje możliwość, że będzie on miało znacznie mniejszy błąd predykcji na zbiorze testowym.


## Testowanie na zbiorze testowym

```{r,results='hold'}
TPrediction1<-predict(Drzewo,zbior_testowy,type = "class")
errorT1<-mean(TPrediction1 != zbior_testowy$`Prawo jazdy`)
print("Błąd predykcji drzewa")
errorT1

TPrediction2<-predict(Drzewo2,zbior_testowy,type = "class")
errorT2<-mean(TPrediction2 != zbior_testowy$`Prawo jazdy`)
print("Błąd predykcji drzewa Przyciętego")
errorT2
```

Teraz możemy ocenić, który model powinniśmy wybrać. Jednak należy pamiętać, że podział na zbiór uczący i testowy jest losowy, więc przy kolejnym uruchomieniu kodu możemy uzyskać inny wynik.


## Rysowanie drzewa
Po dokonaniu wyboru, który model jest lepszy, możemy go przedstawić w postaci wykresu, aby lepiej zobrazować jego działanie.

```{r, results='hold'}
rpart.plot(Drzewo,type = 4,extra="auto")
rpart.plot(Drzewo2,type = 4,extra="auto")
```





